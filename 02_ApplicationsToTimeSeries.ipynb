{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications to Time Series Analysis\n",
    "\n",
    "In this notebook, we demonstrate how to use the Decorated Merge Trees (DMT) framework to understand qualitative topological features of a time series via Takens embeddings.\n",
    "\n",
    "In this notebook, we use decorated merge trees to compare toy point cloud data. The experiments here correspond to Figure 10 from our paper:\n",
    "\n",
    "[1] *Decorated Merge Trees for Persistenct Topology* by Justin Curry, Haibin Hang, Washington Mio, Tom Needham and Osman Okutan. Arxiv: [2103.15804](https://arxiv.org/abs/2103.15804)\n",
    "\n",
    "We will refer back to specific sections of this paper throughout the notebook. For introductions to basic code functionality, please see earlier Jupyter notebooks in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the usual modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ripser import ripser\n",
    "import persim\n",
    "import networkx as nx\n",
    "from sklearn import manifold\n",
    "\n",
    "from DMT_tools import *\n",
    "from example_generating_functions import *\n",
    "\n",
    "import ot\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import the gtda modules\n",
    "from gtda.time_series import Resampler, SingleTakensEmbedding, SlidingWindow, PermutationEntropy\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import Scaler, Filtering, PersistenceEntropy, BettiCurve, PairwiseDistance\n",
    "from gtda.graphs import KNeighborsGraph, GraphGeodesicDistance\n",
    "from gtda.pipeline import Pipeline\n",
    "from gtda.plotting import plot_point_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Embeddings\n",
    "\n",
    "To do TDA on time series, we transform a given time series into a higher-dimensional curve via a *sliding window embedding* or *Takens embedding*. See [this paper](https://link.springer.com/article/10.1007/s10208-014-9206-z) for a precise exposition of the underlying theory. For the readers' convenience, we give a brief description of the process here.\n",
    "\n",
    "Give a time series (i.e., a function) $f:\\mathbb{R} \\to \\mathbb{R}$, we construct the sliding window embedding associated to parameters $d \\in \\mathbb{Z}_{>1}$ and $\\tau \\in \\mathbb{R}_{>0}$ as\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{SW}_{d,\\tau} f: \\mathbb{R} &\\to \\mathbb{R}^{d+1} \\\\\n",
    "t &\\mapsto (f(t),f(t+\\tau),f(t + 2\\tau), \\ldots, f(t+d\\tau)).\n",
    "\\end{align*}\n",
    "\n",
    "Of course, in practice the function $f$ will be defined on a finite interval and we will only have access to finitely many samples of its values. The definition of $\\mathrm{SW}_{d,\\tau}f$ is easily adjusted accordingly. In this discrete setting, the resulting embedding will be a point cloud in $\\mathbb{R}^{d+1}$, and persistent homology of the associated Vietoris-Rips complex gives topological features for the original time series. \n",
    "\n",
    "Generally, practicitioners tend to study the 1-dimensional persistent homology of the embedded point cloud, as this has theoretical ties to periodicity in the original time series. On the other hand, real world time series data frequently contains sharp jumps (change points). These jumps should correspond to persistent **degree-0** features in the embedded point cloud. We use the DMT framework to simultaneuously encode both these change point features and the periodicity coming from degree-1 homology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data\n",
    "\n",
    "We will illustrate the process with synthetic data. We construct data to have periodic behavior, together with a sharp jump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sine Curve Parameters\n",
    "domain_start = 0\n",
    "domain_end = 24*np.pi\n",
    "n_samples = 200\n",
    "freq = 1/2\n",
    "noise_level = 0.1\n",
    "\n",
    "# Construct the periodic signal\n",
    "xs = np.linspace(domain_start,domain_end,n_samples)\n",
    "signal0 = np.sin(xs*freq) + noise_level*np.random.random(n_samples)                \n",
    "\n",
    "# Construct the full signal with a jump\n",
    "signal = np.zeros(len(xs))\n",
    "signal[:100] = signal0[:100]\n",
    "signal[100:200] = signal0[100:200] + 4.5\n",
    "\n",
    "# Plot the result\n",
    "plt.plot(xs,signal)\n",
    "plt.title('Synthetic Time Series Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a Takens embedding (aka sliding window embedding), we'll use the excellent TDA package `giotto`, from which we have already imported several useful functions.\n",
    "\n",
    "The `giotto` Takens embedding function can search over parameters $d,\\tau$, but requires an initial guess, which we input below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 10\n",
    "time_delay = 1\n",
    "\n",
    "embedder = SingleTakensEmbedding(parameters_type='search',dimension=dimension,time_delay=time_delay)\n",
    "embedded_signal = embedder.fit_transform(signal)\n",
    "\n",
    "print('Shape of embedded point cloud:', embedded_signal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of the what the embedded point cloud looks like, we can project to a PCA plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pca_coords = pca.fit_transform(embedded_signal)\n",
    "\n",
    "plt.scatter(pca_coords[:,0],pca_coords[:,1])\n",
    "plt.title('PCA projection of embedded point cloud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the embedded signal seems to have two persistent connected components, each containing a single degree-1 (loop) feature. this reflects the jump in the original time series and the fact that the time series is periodic both before and after the jump.\n",
    "\n",
    "Although there are apparently two distinct primary components, there is some amount of 'chaining' between them. To reduct this effect and accentuate the degree-0 features, we can mildly subsample by density.\n",
    "\n",
    "Note that in a real data analysis pipeline, there are various parameter-selection steps ($d$, $\\tau$, density-based subsampling) that would have to be tuned by cross-validation. We are 'hand selecting' parameters in this simple demonstration, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "# Get a density score for each point\n",
    "DistMat = euclidean_distances(embedded_signal)\n",
    "mean_dist = np.mean(DistMat)\n",
    "densities = [sum(DistMat[j,:] < mean_dist/5) for j in range(embedded_signal.shape[0])]\n",
    "\n",
    "# Subsample by density\n",
    "total_points = 180\n",
    "cutoff = np.sort(densities)[::-1][total_points]\n",
    "# idx = np.argsort(densities)[-total_points:]\n",
    "embedded_signal_subsampled = embedded_signal[densities >= cutoff,:]\n",
    "\n",
    "pca_coords = pca.fit_transform(embedded_signal_subsampled)\n",
    "\n",
    "plt.scatter(pca_coords[:,0],pca_coords[:,1],c = list(range(len(pca_coords))))\n",
    "plt.title('PCA projection of embedded point cloud, \\n subsampled by density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a decorated merge tree for the subsampled embedded point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MT = MergeTree(pointCloud = embedded_signal_subsampled)\n",
    "MT.fit_barcode(degree=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After choosing some threshold parameters to get a clean visualization, we can summarize the topology of the embedded point cloud via a DMT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_thresh = 0.1\n",
    "barcode_thresh = 0.1\n",
    "\n",
    "MT.draw_decorated(tree_thresh,barcode_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that there are two prominent connected components, each of which contains its own degree-1 cycle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the sources of these degree-1 bars in our original time series, but perhaps this would not always be so obvious. We can use the constructed DMT to locate the sources of the bars in the original time series.\n",
    "\n",
    "The process is conceptually simple: for each bar of interest in the DMT, we mark each node descending from the birth point of the bar with an appropriate label. The labels on the nodes give us labels on the points of the original time series, so we can visualize points on the time series which belong to the connected component where a bar was born.\n",
    "\n",
    "This takes a little bit of work to code. First, we will determine indices of points from the subsampled embedded point cloud which belong to each bar's cycle (that is, record the leaves which lie below each of the bars in the decorated merge tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bars = 2\n",
    "\n",
    "node_labels = {}\n",
    "\n",
    "barcode = MT.barcode\n",
    "barcode_lengths = [bar[1]-bar[0] for bar in barcode]\n",
    "barcode_idx_sorted_by_length = np.argsort(barcode_lengths)[::-1]\n",
    "\n",
    "leaf_barcode = MT.leaf_barcode\n",
    "\n",
    "for i in range(num_bars):\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    idx = barcode_idx_sorted_by_length[i]\n",
    "    bar = barcode[idx]\n",
    "    \n",
    "    for leaf, bc in leaf_barcode.items():\n",
    "        if list(bar) in bc:\n",
    "            labels.append(leaf)\n",
    "            \n",
    "    node_labels[i] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can color the plot of the time series signal according to which cycle each point belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,5))\n",
    "plt.plot(xs,signal, c = 'black', alpha = 0.25)\n",
    "\n",
    "idx = [i for i in node_labels[0] if densities[i] > cutoff]\n",
    "x_vals = xs[idx]\n",
    "y_vals = signal[idx]\n",
    "\n",
    "plt.scatter(xs[sorted(idx)],signal[sorted(idx)], c = 'g', s = 10)\n",
    "\n",
    "idx = [i for i in node_labels[1] if densities[i] > cutoff]\n",
    "x_vals = xs[idx]\n",
    "y_vals = signal[idx]\n",
    "\n",
    "plt.scatter(xs[sorted(idx)],signal[sorted(idx)], c = 'b', s = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
